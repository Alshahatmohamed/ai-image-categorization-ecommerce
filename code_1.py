#Phase 1: Exploratory Data Analysis (EDA)
# Import necessary libraries for data handling and visualization
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Set visual style for seaborn
sns.set_style("whitegrid")

# Load the dataset (replace with your actual file path if needed)
df = pd.read_csv("product_data.csv")

# Display the first 5 rows to understand the structure
df.head()
# Check basic info: column names, data types, and missing values
df.info()
# Summary statistics for numerical columns (Price and Rating)
df.describe()
# Count of unique products and categories
print("Total unique products:", df['Product_ID'].nunique())
print("Available categories:", df['Category'].unique())
# Check for missing values across all columns
df.isnull().sum()
# Plot distribution of products by category
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x="Category", palette="Set2")
plt.title("Product Distribution by Category")
plt.xlabel("Category")
plt.ylabel("Count")
plt.tight_layout()
plt.show()
# Plot price distribution using histogram
plt.figure(figsize=(7, 4))
sns.histplot(df['Price'], bins=30, kde=True, color="skyblue")
plt.title("Price Distribution")
plt.xlabel("Price")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()
# Plot rating distribution
plt.figure(figsize=(7, 4))
sns.histplot(df['Rating'], bins=20, kde=True, color="salmon")
plt.title("Rating Distribution")
plt.xlabel("Rating")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()
# Boxplot: Compare price ranges across categories
plt.figure(figsize=(8, 5))
sns.boxplot(data=df, x="Category", y="Price", palette="pastel")
plt.title("Price Comparison by Category")
plt.xlabel("Category")
plt.ylabel("Price")
plt.tight_layout()
plt.show()
# Boxplot: Compare rating across categories
plt.figure(figsize=(8, 5))
sns.boxplot(data=df, x="Category", y="Rating", palette="muted")
plt.title("Rating Comparison by Category")
plt.xlabel("Category")
plt.ylabel("Rating")
plt.tight_layout()
plt.show()


# ----------------------------------------
# Phase 2: Exploratory Data Analysis (EDA)
# ----------------------------------------

# 1. Basic info and statistics
print("Dataset Info:")
df.info()
print("\nSummary Statistics:")
print(df.describe())

# 2. Check for missing values
print("\nMissing Values:")
print(df.isnull().sum())

# 3. Count of products per category
plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Category', palette='pastel')
plt.title("Product Count by Category")
plt.xlabel("Category")
plt.ylabel("Count")
plt.tight_layout()
plt.show()

# 4. Distribution of prices
plt.figure(figsize=(8, 5))
sns.histplot(df['Price'], bins=30, kde=True, color='skyblue')
plt.title("Price Distribution")
plt.xlabel("Price")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()

# 5. Distribution of ratings
plt.figure(figsize=(8, 5))
sns.histplot(df['Rating'], bins=10, kde=True, color='lightgreen')
plt.title("Rating Distribution")
plt.xlabel("Rating")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()

# 6. Boxplot of prices by category
plt.figure(figsize=(8, 5))
sns.boxplot(data=df, x='Category', y='Price', palette='Set2')
plt.title("Price by Category")
plt.xlabel("Category")
plt.ylabel("Price")
plt.tight_layout()
plt.show()

# 7. Relationship between price and rating
plt.figure(figsize=(8, 5))
sns.scatterplot(data=df, x='Price', y='Rating', hue='Category', palette='Set1', alpha=0.7)
plt.title("Price vs Rating")
plt.xlabel("Price")
plt.ylabel("Rating")
plt.tight_layout()
plt.show()


# ==============================
#  Phase 3: Data Analysis & Pattern Discovery
# ==============================

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Set visualization style
sns.set_style("whitegrid")

# Load the dataset
df = pd.read_csv("product_data.csv")

# ------------------------------
#  Statistical Summary
# ------------------------------
print("General Statistical Summary:")
print(df.describe())

# ------------------------------
#  Top Categories by Product Count
# ------------------------------
category_counts = df['Category'].value_counts()

plt.figure(figsize=(8, 5))
sns.barplot(x=category_counts.values, y=category_counts.index, palette='Set2')
plt.title("Top Product Categories by Count")
plt.xlabel("Number of Products")
plt.ylabel("Category")
plt.tight_layout()
plt.show()

# ------------------------------
# Price vs. Rating by Category
# ------------------------------
plt.figure(figsize=(8, 5))
sns.scatterplot(data=df, x="Price", y="Rating", hue="Category", palette="viridis", alpha=0.7)
plt.title("Price vs. Rating by Category")
plt.xlabel("Product Price")
plt.ylabel("Customer Rating")
plt.legend(title="Category", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# ------------------------------
#  Average Price & Rating per Category
# ------------------------------
grouped = df.groupby("Category")[["Price", "Rating"]].mean().sort_values(by="Rating", ascending=False)
print(" Average Price & Rating per Category:\n")
print(grouped)

plt.figure(figsize=(8, 5))
sns.barplot(data=grouped.reset_index(), x="Rating", y="Category", palette="coolwarm")
plt.title("Average Rating by Product Category")
plt.xlabel("Average Rating")
plt.ylabel("Category")
plt.tight_layout()
plt.show()

# ------------------------------
#  Top 5 Best & Worst Rated Products
# ------------------------------
top_rated = df.sort_values(by="Rating", ascending=False).head(5)
worst_rated = df.sort_values(by="Rating", ascending=True).head(5)

print(" Top 5 Rated Products:\n")
print(top_rated[['Product_Name', 'Category', 'Price', 'Rating']])

print("\n Worst 5 Rated Products:\n")
print(worst_rated[['Product_Name', 'Category', 'Price', 'Rating']])


# -----------------------------------
# PHASE 4: MACHINE LEARNING MODEL
# -----------------------------------

#  Step 1: Import required libraries
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

#  Step 2: Prepare the data
# Drop unused columns and define X and y
X = df[["Price", "Rating"]]  # Features
y = df["Category"]           # Target label

#  Step 3: Encode the target (Category)
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

#  Step 4: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42
)
#  Step 5: Train a Random Forest Classifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

#  Step 6: Make predictions
y_pred = model.predict(X_test)

# Step 7: Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(" Model Accuracy:", round(accuracy * 100, 2), "%")
print("\n Classification Report:\n", classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# -----------------------------------
# Phase 5: Image Classification Using Random Forest (Alternative to CNN)
# -----------------------------------

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import numpy as np
import pandas as pd
import os
from PIL import Image

# Load the CSV file
df = pd.read_csv("product_data.csv")  # ‚Üê Change the file name accordingly

# Prepare image data and labels
image_data = []
labels = []

# Process each image
for idx, row in df.iterrows():
    image_path = os.path.join("images_folder", row["Image_URL"])  # ‚Üê Change this to your actual image folder
    try:
        img = Image.open(image_path).resize((64, 64)).convert('RGB')  # Resize and convert to RGB
        img_array = np.array(img).flatten()  # Flatten the image into a 1D array
        image_data.append(img_array)
        labels.append(row["Category"])  # ‚Üê Change this to the name of the label column
    except:
        continue  # Skip if the image is missing or corrupted

# Convert lists to NumPy arrays
X = np.array(image_data)
y = np.array(labels)

# Split the dataset into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Random Forest model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

# -------------------------------------
# PHASE 6: EVALUATION & FINAL SUMMARY
# -------------------------------------

import matplotlib.pyplot as plt
print(history)

# Step 1: Plot training and validation accuracy and loss
plt.figure(figsize=(12, 5))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='green')
plt.title('Model Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', color='red')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Step 2: Evaluate the final model on the validation set
val_loss, val_accuracy = model.evaluate(val_generator)
print(f"\n Final Validation Accuracy: {val_accuracy:.2f}")
print(f"üìâ Final Validation Loss: {val_loss:.2f}")

# Step 3: Final project summary
print("\nüì¶ PROJECT SUMMARY")
print("-" * 60)
print("üîç Goal: Automatically classify real-world e-commerce product images using a pre-trained CNN (MobileNetV2).")
print(f"üìö Transfer Learning used with MobileNetV2 as the base model.")
print(f"üìà CNN trained for {len(history.history['loss'])} epochs.")
print(f"Total images used: {len(df_images)} (Train + Validation).")
print(f"üóÇÔ∏è Categories: {df_images['Category'].nunique()}")
print(f"üéØ Final validation accuracy: {val_accuracy:.2f}")
print("\nüìä The training and validation curves indicate stable learning over time.")
print("‚úÖ The model is now ready to classify new product images into their appropriate categories with high accuracy.")