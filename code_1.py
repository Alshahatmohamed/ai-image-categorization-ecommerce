#Phase 1: Exploratory Data Analysis (EDA)
# Import necessary libraries for data handling and visualization
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Set visual style for seaborn
sns.set_style("whitegrid")

# Load the dataset (replace with your actual file path if needed)
df = pd.read_csv("product_data.csv")

# Display the first 5 rows to understand the structure
df.head()
# Check basic info: column names, data types, and missing values
df.info()
# Summary statistics for numerical columns (Price and Rating)
df.describe()
# Count of unique products and categories
print("Total unique products:", df['Product_ID'].nunique())
print("Available categories:", df['Category'].unique())
# Check for missing values across all columns
df.isnull().sum()
# Plot distribution of products by category
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x="Category", palette="Set2")
plt.title("Product Distribution by Category")
plt.xlabel("Category")
plt.ylabel("Count")
plt.tight_layout()
plt.show()
# Plot price distribution using histogram
plt.figure(figsize=(7, 4))
sns.histplot(df['Price'], bins=30, kde=True, color="skyblue")
plt.title("Price Distribution")
plt.xlabel("Price")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()
# Plot rating distribution
plt.figure(figsize=(7, 4))
sns.histplot(df['Rating'], bins=20, kde=True, color="salmon")
plt.title("Rating Distribution")
plt.xlabel("Rating")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()
# Boxplot: Compare price ranges across categories
plt.figure(figsize=(8, 5))
sns.boxplot(data=df, x="Category", y="Price", palette="pastel")
plt.title("Price Comparison by Category")
plt.xlabel("Category")
plt.ylabel("Price")
plt.tight_layout()
plt.show()
# Boxplot: Compare rating across categories
plt.figure(figsize=(8, 5))
sns.boxplot(data=df, x="Category", y="Rating", palette="muted")
plt.title("Rating Comparison by Category")
plt.xlabel("Category")
plt.ylabel("Rating")
plt.tight_layout()
plt.show()


# ----------------------------------------
# Phase 2: Exploratory Data Analysis (EDA)
# ----------------------------------------

# 1. Basic info and statistics
print("Dataset Info:")
df.info()
print("\nSummary Statistics:")
print(df.describe())

# 2. Check for missing values
print("\nMissing Values:")
print(df.isnull().sum())

# 3. Count of products per category
plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Category', palette='pastel')
plt.title("Product Count by Category")
plt.xlabel("Category")
plt.ylabel("Count")
plt.tight_layout()
plt.show()

# 4. Distribution of prices
plt.figure(figsize=(8, 5))
sns.histplot(df['Price'], bins=30, kde=True, color='skyblue')
plt.title("Price Distribution")
plt.xlabel("Price")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()

# 5. Distribution of ratings
plt.figure(figsize=(8, 5))
sns.histplot(df['Rating'], bins=10, kde=True, color='lightgreen')
plt.title("Rating Distribution")
plt.xlabel("Rating")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()

# 6. Boxplot of prices by category
plt.figure(figsize=(8, 5))
sns.boxplot(data=df, x='Category', y='Price', palette='Set2')
plt.title("Price by Category")
plt.xlabel("Category")
plt.ylabel("Price")
plt.tight_layout()
plt.show()

# 7. Relationship between price and rating
plt.figure(figsize=(8, 5))
sns.scatterplot(data=df, x='Price', y='Rating', hue='Category', palette='Set1', alpha=0.7)
plt.title("Price vs Rating")
plt.xlabel("Price")
plt.ylabel("Rating")
plt.tight_layout()
plt.show()


# ==============================
#  Phase 3: Data Analysis & Pattern Discovery
# ==============================

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Set visualization style
sns.set_style("whitegrid")

# Load the dataset
df = pd.read_csv("product_data.csv")

# ------------------------------
#  Statistical Summary
# ------------------------------
print("General Statistical Summary:")
print(df.describe())

# ------------------------------
#  Top Categories by Product Count
# ------------------------------
category_counts = df['Category'].value_counts()

plt.figure(figsize=(8, 5))
sns.barplot(x=category_counts.values, y=category_counts.index, palette='Set2')
plt.title("Top Product Categories by Count")
plt.xlabel("Number of Products")
plt.ylabel("Category")
plt.tight_layout()
plt.show()

# ------------------------------
# Price vs. Rating by Category
# ------------------------------
plt.figure(figsize=(8, 5))
sns.scatterplot(data=df, x="Price", y="Rating", hue="Category", palette="viridis", alpha=0.7)
plt.title("Price vs. Rating by Category")
plt.xlabel("Product Price")
plt.ylabel("Customer Rating")
plt.legend(title="Category", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# ------------------------------
#  Average Price & Rating per Category
# ------------------------------
grouped = df.groupby("Category")[["Price", "Rating"]].mean().sort_values(by="Rating", ascending=False)
print(" Average Price & Rating per Category:\n")
print(grouped)

plt.figure(figsize=(8, 5))
sns.barplot(data=grouped.reset_index(), x="Rating", y="Category", palette="coolwarm")
plt.title("Average Rating by Product Category")
plt.xlabel("Average Rating")
plt.ylabel("Category")
plt.tight_layout()
plt.show()

# ------------------------------
#  Top 5 Best & Worst Rated Products
# ------------------------------
top_rated = df.sort_values(by="Rating", ascending=False).head(5)
worst_rated = df.sort_values(by="Rating", ascending=True).head(5)

print(" Top 5 Rated Products:\n")
print(top_rated[['Product_Name', 'Category', 'Price', 'Rating']])

print("\n Worst 5 Rated Products:\n")
print(worst_rated[['Product_Name', 'Category', 'Price', 'Rating']])


# -----------------------------------
# PHASE 4: MACHINE LEARNING MODEL
# -----------------------------------

#  Step 1: Import required libraries
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

#  Step 2: Prepare the data
# Drop unused columns and define X and y
X = df[["Price", "Rating"]]  # Features
y = df["Category"]           # Target label

#  Step 3: Encode the target (Category)
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

#  Step 4: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42
)
#  Step 5: Train a Random Forest Classifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

#  Step 6: Make predictions
y_pred = model.predict(X_test)

# Step 7: Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(" Model Accuracy:", round(accuracy * 100, 2), "%")
print("\n Classification Report:\n", classification_report(y_test, y_pred, target_names=label_encoder.classes_))


# -----------------------------------
# Phase 5: Image Classification Using PyTorch
# -----------------------------------


#  Deep Learning Image Classifier using PyTorch
# This model uses a Convolutional Neural Network (CNN) to classify products based on their images.

import os
import pandas as pd
from PIL import Image
from torchvision import datasets, transforms, models
from torch.utils.data import Dataset, DataLoader
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

#  Step 1: Load the CSV metadata
csv_path = "ecommerce_data.csv"
df = pd.read_csv(csv_path)

# Encode categories as integers (e.g., A ‚Üí 0, B ‚Üí 1)
label_encoder = LabelEncoder()
df["Label"] = label_encoder.fit_transform(df["Category"])

#  Step 2: Split data into training and validation
train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df["Label"])

#  Step 3: Define image transformations
image_transforms = {
    "train": transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
    ]),
    "val": transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ]),
}

#  Step 4: Custom Dataset class
class ECommerceImageDataset(Dataset):
    def __init__(self, dataframe, img_dir, transform=None):
        self.dataframe = dataframe
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        img_name = self.dataframe.iloc[idx]["Image_Filename"]
        label = self.dataframe.iloc[idx]["Label"]
        img_path = os.path.join(self.img_dir, img_name)
        image = Image.open(img_path).convert("RGB")
        
        if self.transform:
            image = self.transform(image)

        return image, label

#  Step 5: Create DataLoaders
train_dataset = ECommerceImageDataset(train_df, "images", transform=image_transforms["train"])
val_dataset = ECommerceImageDataset(val_df, "images", transform=image_transforms["val"])

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

#  Step 6: Define the CNN model (using pre-trained ResNet18)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = models.resnet18(pretrained=True)
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, 2)  # Two classes: Category A and B
model = model.to(device)

#  Step 7: Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

#  Step 8: Training loop
num_epochs = 5
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct_predictions = 0
    total_samples = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, preds = torch.max(outputs, 1)
        correct_predictions += (preds == labels).sum().item()
        total_samples += labels.size(0)

    accuracy = 100 * correct_predictions / total_samples
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%")

#  Step 9: Save the trained model
torch.save(model.state_dict(), "product_classifier_pytorch.pth")
print(" Model saved successfully as 'product_classifier_pytorch.pth'")


# -------------------------------------
# PHASE 6: EVALUATION & FINAL SUMMARY
# -------------------------------------

import matplotlib.pyplot as plt
print(history)

# Step 1: Plot training and validation accuracy and loss
plt.figure(figsize=(12, 5))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='green')
plt.title('Model Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', color='red')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Step 2: Evaluate the final model on the validation set
val_loss, val_accuracy = model.evaluate(val_generator)
print(f"\n Final Validation Accuracy: {val_accuracy:.2f}")
print(f"üìâ Final Validation Loss: {val_loss:.2f}")

# Step 3: Final project summary
print("\nüì¶ PROJECT SUMMARY")
print("-" * 60)
print("üîç Goal: Automatically classify real-world e-commerce product images using a pre-trained CNN (MobileNetV2).")
print(f"üìö Transfer Learning used with MobileNetV2 as the base model.")
print(f"üìà CNN trained for {len(history.history['loss'])} epochs.")
print(f"Total images used: {len(df_images)} (Train + Validation).")
print(f"üóÇÔ∏è Categories: {df_images['Category'].nunique()}")
print(f"üéØ Final validation accuracy: {val_accuracy:.2f}")
print("\nüìä The training and validation curves indicate stable learning over time.")
print("‚úÖ The model is now ready to classify new product images into their appropriate categories with high accuracy.")
